
### 问题  

* 起飞后总是固定一个方向飞行，并撞墙
* 在撞墙之前都不会有偏转角度
* 有时会出现连续无法起飞的情况

#### 总之目前的主要问题是：
1. 总是采取固定的动作，很少尝试新动作
2. 奖励函数设定的惩罚不起作用


#### 可能的原因：
1. 学习能力不够，或者学习太慢
2. 探索性不足  

#### 解决思路
1. 奖励函数设置是否还有不合理之处
2. 继续调整 Actor 和 Critic 网络模型
3. 目前采用 Ornstein-Uhlenbeck 加入随机噪点，是否需要更改参数设定；或者换用其他的探索机制尝试，比如 Epsilon贪婪算法
4. 记忆回放机制有待调整


## 最新发现

为了简化问题，限制了动作状态空间，只施加了z方向的线性推力，其他动作向量都为0，相应的状态空间也只考虑高度向量

在takeoff任务和hover任务上进行试验

### takeoff
* 刚开始force_z一直为负，经过一段时间后纠正过来，到后期每次都能稳定起飞
* 从奖励曲线上看，也比之前采用三个动作向量的效果好，累积奖励收敛的很快，并一直保持平稳

### hover
* Trail01：始终无法起飞，但一直在不断探索，改变动作，force_z忽高忽低，一直在正负值波动

#### 调试-1：更改奖励函数
* 5秒之内不起飞，给负奖励，起飞成功给正奖励，不会结束阶段
 Trail02：很快起飞，一直上升不减速
* 去掉了起飞成功的正奖励
仍旧没有改变
* 加大高度差的惩罚力度
还是没有效果

* 增加了高度限制，如果高度超过15，终止阶段（并惩罚）
不再是直飞冲天，前半段一直无法起飞，不停跳动；后半段起飞后仍旧不能减速，总是超出限制

* 增加维持高度稳定的奖励，如果高度与目标的差在0.5之内
没有明显效果

* 把高度偏离的惩罚改为二次函数，取消高度限制和超出高度的额外惩罚（额外惩罚为固定常数），只保留维持高度稳定的正奖励

* 把高度偏离惩罚改为指数函数，高度限制设定在50
Trail03：惩罚过大会导致NAN
但貌似有点效果，刚开始试验出现了升高以后又下落的动作（但下落太快）


#### 分析
* 指数式放大的惩罚可能有用，但必须要限制范围，或者仍采用高次函数，然后起飞惩罚也与此一致
* 智能体模型还有待赶紧

