### 奖励函数方案
```
time < 5s:
    R+ = min(abs(height_diff),20) 与take off 设定一致
time > 5s:

	if haven't rearch target height:
		R- 30

	R - abs(height_diff)^3   #高度偏离惩罚，3次函数

	if abs(height_diff) < 0.5:
		R+100                #高度稳定奖励

	if flys too high or time is up:
		done = True
```

### 目前表现
一直很稳定的起飞并持续加速上升，而且每次的动作都很固定


### 调试

#### DDPG模型调试

1. gamma 由0.99 改为 0.9，又改为0.8
没有效果

2. 尝试调整随机噪点
Ornstein–Uhlenbeck process，根据维基百科，分布曲线的长期固定方差为：
var = sigma^2/2theta
sigma越大，theta越小，会使得方差越大，产生的随机数变动的幅度也就越大
因此决定往方差更大的方向调整，看会不会促进随机探索

*  sigma = 0.3 theta=0.1
Trial_01 : 明显发现随机探索增强了，刚开始飞出边界后，开始尝试下落和减速，但动作不稳定，到后期就在地面附近上下跳动，不能起飞的情况
记录下了阶段累积奖励 rewards_hover_01.txt 和每个时间步的动作向量 actions_hover_01.txt
也许是因为超出目标高度的惩罚是3次函数，而起飞惩罚只是常数，智能体宁愿停留在地面不动

* 尝试把起飞惩罚也调成3次函数